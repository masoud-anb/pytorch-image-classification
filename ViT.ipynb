{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsR6bH-nfdzu",
        "outputId": "8a449107-8428-45b5-9c46-6f4dec307cd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g870O4m1hnXC",
        "outputId": "df17a2bb-ae09-40a2-9b80-aece9230f368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping case1...\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "###  !rm -rf <folder_name>\n",
        "\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path\n",
        "\n",
        "with zipfile.ZipFile(\"drive/MyDrive/emp/case1.zip\", \"r\") as zip_ref:\n",
        "  print(\"Unzipping case1...\")\n",
        "  zip_ref.extractall(image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "A4pbXwjsqQL6"
      },
      "outputs": [],
      "source": [
        "# # For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
        "# try:\n",
        "#     import torch\n",
        "#     import torchvision\n",
        "#     assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
        "#     assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
        "#     print(f\"torch version: {torch.__version__}\")\n",
        "#     print(f\"torchvision version: {torchvision.__version__}\")\n",
        "# except:\n",
        "#     print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
        "#     !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "#     import torch\n",
        "#     import torchvision\n",
        "#     print(f\"torch version: {torch.__version__}\")\n",
        "#     print(f\"torchvision version: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9ah_W9pqZoR",
        "outputId": "3edf2784-92db-40f4-f009-3bcff361a9ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n",
            "[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.\n",
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 4393, done.\u001b[K\n",
            "remote: Total 4393 (delta 0), reused 0 (delta 0), pack-reused 4393 (from 1)\u001b[K\n",
            "Receiving objects: 100% (4393/4393), 764.14 MiB | 16.28 MiB/s, done.\n",
            "Resolving deltas: 100% (2656/2656), done.\n",
            "Updating files: 100% (248/248), done.\n"
          ]
        }
      ],
      "source": [
        "# Continue with regular imports\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "    from helper_functions import download_data, set_seeds, plot_loss_curves\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !mv pytorch-deep-learning/helper_functions.py . # get the helper_functions.py script\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "    from helper_functions import download_data, set_seeds, plot_loss_curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nW9pye5sqZwo",
        "outputId": "d441bc48-e6fa-4286-fe73-5836e7fb68ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeHxv2bGqZ0R"
      },
      "outputs": [],
      "source": [
        "# Setup Dirs\n",
        "# train_dir = image_path / \"emp/case/train\"\n",
        "# test_dir = image_path / \"emp/case/test\"\n",
        "\n",
        "# train_dir , test_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13MS6Wa2Jt2U"
      },
      "outputs": [],
      "source": [
        "# Setup dirs\n",
        "train_dir = image_path / \"case1/train\"\n",
        "test_dir = image_path / \"case1/test\"\n",
        "\n",
        "# # Setup pretrained weights (plenty of these available in torchvision.models)\n",
        "# weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "\n",
        "# # Get transforms from weights (these are the transforms that were used to obtain the weights)\n",
        "# automatic_transforms = weights.transforms()\n",
        "# print(f\"Automatically created transforms: {automatic_transforms}\")\n",
        "\n",
        "# # Create data loaders\n",
        "# train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
        "#     train_dir=train_dir,\n",
        "#     test_dir=test_dir,\n",
        "#     transform=automatic_transforms, # use automatic created transforms\n",
        "#     batch_size=32\n",
        "# )\n",
        "\n",
        "# train_dataloader, test_dataloader, class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTEZ6_nnTXB0"
      },
      "outputs": [],
      "source": [
        "# try:\n",
        "#     from torch.utils.tensorboard import SummaryWriter\n",
        "# except:\n",
        "#     print(\"[INFO] Couldn't find tensorboard... installing it.\")\n",
        "#     !pip install -q tensorboard\n",
        "#     from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "# # Create a writer with all default settings\n",
        "# writer = SummaryWriter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tPX8eA0Y3Fw"
      },
      "outputs": [],
      "source": [
        "# def create_writer(experiment_name: str,\n",
        "#                   model_name: str,\n",
        "#                   extra: str=None) -> torch.utils.tensorboard.writer.SummaryWriter():\n",
        "#     \"\"\"Creates a torch.utils.tensorboard.writer.SummaryWriter() instance saving to a specific log_dir.\n",
        "\n",
        "#     log_dir is a combination of runs/timestamp/experiment_name/model_name/extra.\n",
        "\n",
        "#     Where timestamp is the current date in YYYY-MM-DD format.\n",
        "\n",
        "#     Args:\n",
        "#         experiment_name (str): Name of experiment.\n",
        "#         model_name (str): Name of model.\n",
        "#         extra (str, optional): Anything extra to add to the directory. Defaults to None.\n",
        "\n",
        "#     Returns:\n",
        "#         torch.utils.tensorboard.writer.SummaryWriter(): Instance of a writer saving to log_dir.\n",
        "\n",
        "#     Example usage:\n",
        "#         # Create a writer saving to \"runs/2022-06-04/data_10_percent/effnetb2/5_epochs/\"\n",
        "#         writer = create_writer(experiment_name=\"data_10_percent\",\n",
        "#                                model_name=\"effnetb2\",\n",
        "#                                extra=\"5_epochs\")\n",
        "#         # The above is the same as:\n",
        "#         writer = SummaryWriter(log_dir=\"runs/2022-06-04/data_10_percent/effnetb2/5_epochs/\")\n",
        "#     \"\"\"\n",
        "#     from datetime import datetime\n",
        "#     import os\n",
        "\n",
        "#     # Get timestamp of current date (all experiments on certain day live in same folder)\n",
        "#     timestamp = datetime.now().strftime(\"%Y-%m-%d\") # returns current date in YYYY-MM-DD format\n",
        "\n",
        "#     if extra:\n",
        "#         # Create log directory path\n",
        "#         log_dir = os.path.join(\"runs\", timestamp, str(experiment_name), model_name, extra)\n",
        "#     else:\n",
        "#         log_dir = os.path.join(\"runs\", timestamp, str(experiment_name), model_name)\n",
        "\n",
        "#     print(f\"[INFO] Created SummaryWriter, saving to: {log_dir}...\")\n",
        "#     return SummaryWriter(log_dir=log_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2AF8-4XTgEI"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from going_modular.going_modular.engine import train_step, test_step\n",
        "\n",
        "# Import train() function from:\n",
        "# https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/going_modular/engine.py\n",
        "from typing import Dict, List\n",
        "from tqdm.auto import tqdm\n",
        "import wandb\n",
        "\n",
        "\n",
        "# Add writer parameter to train()\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device,\n",
        "          # writer: torch.utils.tensorboard.writer.SummaryWriter # new parameter to take in a writer\n",
        "          ) -> Dict[str, List]:\n",
        "    \"\"\"Trains and tests a PyTorch model.\n",
        "\n",
        "    Passes a target PyTorch models through train_step() and test_step()\n",
        "    functions for a number of epochs, training and testing the model\n",
        "    in the same epoch loop.\n",
        "\n",
        "    Calculates, prints and stores evaluation metrics throughout.\n",
        "\n",
        "    Stores metrics to specified writer log_dir if present.\n",
        "\n",
        "    Args:\n",
        "      model: A PyTorch model to be trained and tested.\n",
        "      train_dataloader: A DataLoader instance for the model to be trained on.\n",
        "      test_dataloader: A DataLoader instance for the model to be tested on.\n",
        "      optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "      loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
        "      epochs: An integer indicating how many epochs to train for.\n",
        "      device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "      writer: A SummaryWriter() instance to log model results to.\n",
        "\n",
        "    Returns:\n",
        "      A dictionary of training and testing loss as well as training and\n",
        "      testing accuracy metrics. Each metric has a value in a list for\n",
        "      each epoch.\n",
        "      In the form: {train_loss: [...],\n",
        "                train_acc: [...],\n",
        "                test_loss: [...],\n",
        "                test_acc: [...]}\n",
        "      For example if training for epochs=2:\n",
        "              {train_loss: [2.0616, 1.0537],\n",
        "                train_acc: [0.3945, 0.3945],\n",
        "                test_loss: [1.2641, 1.5706],\n",
        "                test_acc: [0.3400, 0.2973]}\n",
        "    \"\"\"\n",
        "    # Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "               \"train_acc\": [],\n",
        "               \"test_loss\": [],\n",
        "               \"test_acc\": []\n",
        "    }\n",
        "\n",
        "    # Loop through training and testing steps for a number of epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                          dataloader=train_dataloader,\n",
        "                                          loss_fn=loss_fn,\n",
        "                                          optimizer=optimizer,\n",
        "                                          device=device)\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "                                        dataloader=test_dataloader,\n",
        "                                        loss_fn=loss_fn,\n",
        "                                        device=device)\n",
        "\n",
        "        # Print out what's happening\n",
        "        print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Update results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "\n",
        "        ### New: Use the writer parameter to track experiments ###\n",
        "        # See if there's a writer, if so, log to it\n",
        "        # if writer:\n",
        "        #     # Add results to SummaryWriter\n",
        "        #     writer.add_scalars(main_tag=\"Loss\",\n",
        "        #                        tag_scalar_dict={\"train_loss\": train_loss,\n",
        "        #                                         \"test_loss\": test_loss},\n",
        "        #                        global_step=epoch)\n",
        "        #     writer.add_scalars(main_tag=\"Accuracy\",\n",
        "        #                        tag_scalar_dict={\"train_acc\": train_acc,\n",
        "        #                                         \"test_acc\": test_acc},\n",
        "        #                        global_step=epoch)\n",
        "\n",
        "        #     # Close the writer\n",
        "        #     writer.close()\n",
        "        # else:\n",
        "        #     pass\n",
        "        ### End new ###\n",
        "\n",
        "        # Log metrics to wandb\n",
        "        wandb.log({\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_acc\": train_acc,\n",
        "            \"test_loss\": test_loss,\n",
        "            \"test_acc\": test_acc,\n",
        "            \"epoch\": epoch + 1\n",
        "        })\n",
        "\n",
        "\n",
        "    # Return the filled results at the end of the epochs\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7LfeTbXmI7b",
        "outputId": "3c380bee-746b-4460-e083-2390a54ee53c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically created transforms: ImageClassification(\n",
            "    crop_size=[224]\n",
            "    resize_size=[256]\n",
            "    mean=[0.485, 0.456, 0.406]\n",
            "    std=[0.229, 0.224, 0.225]\n",
            "    interpolation=InterpolationMode.BILINEAR\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Setup pretrained weights (plenty of these available in torchvision.models)\n",
        "pretrained_vit_weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
        "\n",
        "\n",
        "# Get transforms from weights (these are the transforms that were used to obtain the weights)\n",
        "vit_transforms = pretrained_vit_weights.transforms()\n",
        "print(f\"Automatically created transforms: {vit_transforms}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Noukg7shmJQi"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create vit training and test DataLoaders\n",
        "train_dataloader_vit, test_dataloader_vit, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    transform=vit_transforms,\n",
        "    batch_size=BATCH_SIZE)\n",
        "# Could increase if we had more samples, such as here: https://arxiv.org/abs/2205.01580 (there are other improvements there too...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCRMl7108Kk3"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torch import nn\n",
        "\n",
        "# Get num out features (one for each class pizza, steak, sushi)\n",
        "OUT_FEATURES = len(class_names)\n",
        "\n",
        "# vit_weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
        "\n",
        "\n",
        "#6. Create an vit feature extractor\n",
        "def create_vit():\n",
        "    # 1. Get the base model with pretrained weights and send to target device\n",
        "    vit_weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
        "    # 2. Setup a ViT model instance with pretrained weights\n",
        "    model = torchvision.models.vit_b_16(weights=vit_weights).to(device)\n",
        "\n",
        "    # 3. Freeze the base parameters\n",
        "    for parameter in model.parameters():\n",
        "        parameter.requires_grad = False\n",
        "\n",
        "    # 4. Change the classifier head (set the seeds to ensure same initialization with linear head)\n",
        "    model.heads = nn.Linear(in_features=768, out_features=len(class_names)).to(device)\n",
        "\n",
        "    # 5. Give the model a name\n",
        "    model.name = \"vit16\"\n",
        "    print(f\"[INFO] Created new {model.name} model.\")\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41OWZ27n8IdY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f4047e2-e537-4cc8-e756-1a5c6448c3b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Created new vit16 model.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
              "============================================================================================================================================\n",
              "VisionTransformer (VisionTransformer)                        [32, 3, 224, 224]    [32, 2]              768                  Partial\n",
              "├─Conv2d (conv_proj)                                         [32, 3, 224, 224]    [32, 768, 14, 14]    (590,592)            False\n",
              "├─Encoder (encoder)                                          [32, 197, 768]       [32, 197, 768]       151,296              False\n",
              "│    └─Dropout (dropout)                                     [32, 197, 768]       [32, 197, 768]       --                   --\n",
              "│    └─Sequential (layers)                                   [32, 197, 768]       [32, 197, 768]       --                   False\n",
              "│    │    └─EncoderBlock (encoder_layer_0)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_1)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_2)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_3)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_4)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_5)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_6)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_7)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_8)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_9)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_10)                  [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_11)                  [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    └─LayerNorm (ln)                                        [32, 197, 768]       [32, 197, 768]       (1,536)              False\n",
              "├─Linear (heads)                                             [32, 768]            [32, 2]              1,538                True\n",
              "============================================================================================================================================\n",
              "Total params: 85,800,194\n",
              "Trainable params: 1,538\n",
              "Non-trainable params: 85,798,656\n",
              "Total mult-adds (Units.GIGABYTES): 5.52\n",
              "============================================================================================================================================\n",
              "Input size (MB): 19.27\n",
              "Forward/backward pass size (MB): 3330.74\n",
              "Params size (MB): 229.20\n",
              "Estimated Total Size (MB): 3579.20\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "vit16 = create_vit()\n",
        "\n",
        "# Print a summary using torchinfo (uncomment for actual output)\n",
        "summary(model=vit16,\n",
        "        input_size=(32, 3, 224, 224), # (batch_size, color_channels, height, width)\n",
        "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsCMfupZO_Op"
      },
      "outputs": [],
      "source": [
        "# 1. Create epochs list\n",
        "num_epochs = 50\n",
        "\n",
        "# 2. Create models list (need to create a new model for each experiment)\n",
        "models = [\"vit16\"]\n",
        "\n",
        "# 3. Create dataloaders dictionary for various dataloaders\n",
        "# train_dataloaders = {\"data_train_effnet\": train_dataloader_effnet,\n",
        "#                      \"data_train_inception\": train_dataloader_inception,\n",
        "#                      \"data_train_mobilenet\": train_dataloader_mobilenet,\n",
        "#                      \"data_train_resnet50\": train_dataloader_resnet50,\n",
        "#                      \"data_train_vgg16\": train_dataloader_vgg16}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "DJL5omZkk4sz",
        "outputId": "af877166-6a93-4402-a926-78f85055833e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellesar\u001b[0m (\u001b[33mellesar-srbiau\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d3a84a726a4c4a92bdc90db15d7e89cf",
            "3c55ae56e713441caafcd1d924ca1904",
            "a50ea1589c39430e924910b900584375",
            "46da477fc610406ea75b9490391ed8ca",
            "b26d7f1656f64ee8a2cc49c57991ebf9",
            "2044f565b6274a49a0d33b2b7100d371",
            "8e6cd7984424411ca2e386f1243d619f",
            "3332552953e64ca1a1ab48e2486c35d0",
            "c07dcbba560a40adbd136c7fc8dd7de7",
            "7f9aa94a81e843c39643879132f6d069",
            "c9afe4bd0bf24cc6b338dae8cc069223"
          ]
        },
        "id": "QHzG73vJO_TT",
        "outputId": "8334167a-6c1c-4135-8366-eb257bfec91a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Experiment number: 1\n",
            "[INFO] Model: vit16\n",
            "[INFO] Number of epochs: 50\n",
            "[INFO] Created new vit16 model.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250718_125225-f1rygrbr</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ellesar-srbiau/your-project-name/runs/f1rygrbr' target=\"_blank\">vit16_50_epochs_exp_1</a></strong> to <a href='https://wandb.ai/ellesar-srbiau/your-project-name' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ellesar-srbiau/your-project-name' target=\"_blank\">https://wandb.ai/ellesar-srbiau/your-project-name</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ellesar-srbiau/your-project-name/runs/f1rygrbr' target=\"_blank\">https://wandb.ai/ellesar-srbiau/your-project-name/runs/f1rygrbr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3a84a726a4c4a92bdc90db15d7e89cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.5386 | train_acc: 0.7363 | test_loss: 0.3679 | test_acc: 0.8672\n",
            "Epoch: 2 | train_loss: 0.2986 | train_acc: 0.9056 | test_loss: 0.2319 | test_acc: 0.9609\n",
            "Epoch: 3 | train_loss: 0.2097 | train_acc: 0.9395 | test_loss: 0.1868 | test_acc: 0.9688\n",
            "Epoch: 4 | train_loss: 0.1649 | train_acc: 0.9531 | test_loss: 0.1817 | test_acc: 0.9297\n",
            "Epoch: 5 | train_loss: 0.1439 | train_acc: 0.9570 | test_loss: 0.1307 | test_acc: 0.9766\n",
            "Epoch: 6 | train_loss: 0.1232 | train_acc: 0.9746 | test_loss: 0.1251 | test_acc: 0.9844\n",
            "Epoch: 7 | train_loss: 0.1073 | train_acc: 0.9844 | test_loss: 0.1151 | test_acc: 0.9844\n",
            "Epoch: 8 | train_loss: 0.0974 | train_acc: 0.9863 | test_loss: 0.1024 | test_acc: 0.9766\n",
            "Epoch: 9 | train_loss: 0.0840 | train_acc: 0.9941 | test_loss: 0.0984 | test_acc: 0.9844\n",
            "Epoch: 10 | train_loss: 0.0839 | train_acc: 0.9844 | test_loss: 0.0856 | test_acc: 0.9844\n",
            "Epoch: 11 | train_loss: 0.0739 | train_acc: 0.9922 | test_loss: 0.0805 | test_acc: 0.9844\n",
            "Epoch: 12 | train_loss: 0.0653 | train_acc: 0.9961 | test_loss: 0.0776 | test_acc: 0.9844\n",
            "Epoch: 13 | train_loss: 0.0595 | train_acc: 0.9941 | test_loss: 0.0721 | test_acc: 0.9922\n",
            "Epoch: 14 | train_loss: 0.0556 | train_acc: 0.9961 | test_loss: 0.0669 | test_acc: 1.0000\n",
            "Epoch: 15 | train_loss: 0.0507 | train_acc: 0.9961 | test_loss: 0.0636 | test_acc: 0.9922\n",
            "Epoch: 16 | train_loss: 0.0500 | train_acc: 0.9961 | test_loss: 0.0619 | test_acc: 0.9922\n",
            "Epoch: 17 | train_loss: 0.0462 | train_acc: 0.9961 | test_loss: 0.0611 | test_acc: 0.9922\n",
            "Epoch: 18 | train_loss: 0.0458 | train_acc: 0.9961 | test_loss: 0.0609 | test_acc: 0.9922\n",
            "Epoch: 19 | train_loss: 0.0413 | train_acc: 0.9961 | test_loss: 0.0548 | test_acc: 1.0000\n",
            "Epoch: 20 | train_loss: 0.0408 | train_acc: 0.9980 | test_loss: 0.0513 | test_acc: 1.0000\n",
            "Epoch: 21 | train_loss: 0.0391 | train_acc: 0.9980 | test_loss: 0.0537 | test_acc: 0.9922\n",
            "Epoch: 22 | train_loss: 0.0336 | train_acc: 0.9980 | test_loss: 0.0474 | test_acc: 1.0000\n",
            "Epoch: 23 | train_loss: 0.0329 | train_acc: 1.0000 | test_loss: 0.0475 | test_acc: 1.0000\n",
            "Epoch: 24 | train_loss: 0.0308 | train_acc: 1.0000 | test_loss: 0.0459 | test_acc: 1.0000\n",
            "Epoch: 25 | train_loss: 0.0298 | train_acc: 1.0000 | test_loss: 0.0429 | test_acc: 1.0000\n",
            "Epoch: 26 | train_loss: 0.0287 | train_acc: 1.0000 | test_loss: 0.0417 | test_acc: 1.0000\n",
            "Epoch: 27 | train_loss: 0.0278 | train_acc: 1.0000 | test_loss: 0.0414 | test_acc: 1.0000\n",
            "Epoch: 28 | train_loss: 0.0257 | train_acc: 1.0000 | test_loss: 0.0405 | test_acc: 1.0000\n",
            "Epoch: 29 | train_loss: 0.0242 | train_acc: 1.0000 | test_loss: 0.0392 | test_acc: 1.0000\n",
            "Epoch: 30 | train_loss: 0.0231 | train_acc: 1.0000 | test_loss: 0.0381 | test_acc: 1.0000\n",
            "Epoch: 31 | train_loss: 0.0230 | train_acc: 1.0000 | test_loss: 0.0367 | test_acc: 1.0000\n",
            "Epoch: 32 | train_loss: 0.0213 | train_acc: 1.0000 | test_loss: 0.0363 | test_acc: 1.0000\n",
            "Epoch: 33 | train_loss: 0.0210 | train_acc: 1.0000 | test_loss: 0.0354 | test_acc: 1.0000\n",
            "Epoch: 34 | train_loss: 0.0210 | train_acc: 1.0000 | test_loss: 0.0329 | test_acc: 1.0000\n",
            "Epoch: 35 | train_loss: 0.0206 | train_acc: 1.0000 | test_loss: 0.0344 | test_acc: 1.0000\n",
            "Epoch: 36 | train_loss: 0.0185 | train_acc: 1.0000 | test_loss: 0.0313 | test_acc: 1.0000\n",
            "Epoch: 37 | train_loss: 0.0195 | train_acc: 1.0000 | test_loss: 0.0327 | test_acc: 1.0000\n",
            "Epoch: 38 | train_loss: 0.0174 | train_acc: 1.0000 | test_loss: 0.0315 | test_acc: 1.0000\n",
            "Epoch: 39 | train_loss: 0.0172 | train_acc: 1.0000 | test_loss: 0.0300 | test_acc: 1.0000\n",
            "Epoch: 40 | train_loss: 0.0161 | train_acc: 1.0000 | test_loss: 0.0297 | test_acc: 1.0000\n",
            "Epoch: 41 | train_loss: 0.0155 | train_acc: 1.0000 | test_loss: 0.0304 | test_acc: 1.0000\n",
            "Epoch: 42 | train_loss: 0.0149 | train_acc: 1.0000 | test_loss: 0.0285 | test_acc: 1.0000\n",
            "Epoch: 43 | train_loss: 0.0146 | train_acc: 1.0000 | test_loss: 0.0276 | test_acc: 1.0000\n",
            "Epoch: 44 | train_loss: 0.0139 | train_acc: 1.0000 | test_loss: 0.0275 | test_acc: 1.0000\n",
            "Epoch: 45 | train_loss: 0.0156 | train_acc: 1.0000 | test_loss: 0.0280 | test_acc: 1.0000\n",
            "Epoch: 46 | train_loss: 0.0134 | train_acc: 1.0000 | test_loss: 0.0268 | test_acc: 1.0000\n",
            "Epoch: 47 | train_loss: 0.0134 | train_acc: 1.0000 | test_loss: 0.0263 | test_acc: 1.0000\n",
            "Epoch: 48 | train_loss: 0.0130 | train_acc: 1.0000 | test_loss: 0.0268 | test_acc: 1.0000\n",
            "Epoch: 49 | train_loss: 0.0135 | train_acc: 1.0000 | test_loss: 0.0267 | test_acc: 1.0000\n",
            "Epoch: 50 | train_loss: 0.0122 | train_acc: 1.0000 | test_loss: 0.0240 | test_acc: 1.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_acc</td><td>▁▆▆▄▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>test_loss</td><td>█▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇███████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>50</td></tr><tr><td>test_acc</td><td>1</td></tr><tr><td>test_loss</td><td>0.02395</td></tr><tr><td>train_acc</td><td>1</td></tr><tr><td>train_loss</td><td>0.01216</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">vit16_50_epochs_exp_1</strong> at: <a href='https://wandb.ai/ellesar-srbiau/your-project-name/runs/f1rygrbr' target=\"_blank\">https://wandb.ai/ellesar-srbiau/your-project-name/runs/f1rygrbr</a><br> View project at: <a href='https://wandb.ai/ellesar-srbiau/your-project-name' target=\"_blank\">https://wandb.ai/ellesar-srbiau/your-project-name</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250718_125225-f1rygrbr/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Saving model to: models/01_vit16_50_epochs.pth\n",
            "--------------------------------------------------\n",
            "\n",
            "CPU times: user 4min 52s, sys: 13.8 s, total: 5min 6s\n",
            "Wall time: 7min 40s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from going_modular.going_modular.utils import save_model\n",
        "import wandb\n",
        "\n",
        "\n",
        "# 1. Set the random seeds\n",
        "# set_seeds(seed=42)\n",
        "\n",
        "# 2. Keep track of experiment numbers\n",
        "experiment_number = 0\n",
        "\n",
        "for model_name in models:\n",
        "\n",
        "    # 6. Create information print outs\n",
        "    experiment_number += 1\n",
        "    print(f\"[INFO] Experiment number: {experiment_number}\")\n",
        "    print(f\"[INFO] Model: {model_name}\")\n",
        "    #print(f\"[INFO] DataLoader: {dataloader_name}\")\n",
        "    print(f\"[INFO] Number of epochs: {num_epochs}\")\n",
        "\n",
        "    # 7. Select the model\n",
        "\n",
        "    if model_name == \"vit16\":\n",
        "        model = create_vit() # creates a new model each time (important because we want each experiment to start from scratch)\n",
        "        train_dataloader=train_dataloader_vit\n",
        "        test_dataloader=test_dataloader_vit\n",
        "\n",
        "\n",
        "    # 8. Create a new loss and optimizer for every model\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "    # Initialize a new wandb run for each experiment\n",
        "    wandb.init(project=\"your-project-name\",\n",
        "               name=f\"{model_name}_{num_epochs}_epochs_exp_{experiment_number}\",\n",
        "               config={\n",
        "                   \"model_name\": model_name,\n",
        "                   \"num_epochs\": num_epochs,\n",
        "                   \"batch_size\": BATCH_SIZE,\n",
        "                   \"learning_rate\": 0.001,\n",
        "                   \"loss_fn\": loss_fn.__class__.__name__,\n",
        "                   \"optimizer\": optimizer.__class__.__name__\n",
        "               })\n",
        "\n",
        "\n",
        "    # 9. Train target model with target dataloaders and track experiments\n",
        "    train(model=model,\n",
        "          train_dataloader=train_dataloader,\n",
        "          test_dataloader=test_dataloader,\n",
        "          optimizer=optimizer,\n",
        "          loss_fn=loss_fn,\n",
        "          epochs=num_epochs,\n",
        "          device=device,\n",
        "        #   writer=create_writer(experiment_name=experiment_number,\n",
        "        #                         model_name=model_name,\n",
        "        #                         extra=f\"{num_epochs}_epochs\")\n",
        "          )\n",
        "\n",
        "    # Finish the wandb run\n",
        "    wandb.finish()\n",
        "\n",
        "    # 10. Save the model to file so we can get back the best model\n",
        "    save_filepath = f\"01_{model_name}_{num_epochs}_epochs.pth\"\n",
        "    save_model(model=model,\n",
        "                target_dir=\"models\",\n",
        "                model_name=save_filepath)\n",
        "    print(\"-\"*50 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNzMXpkuPhcy"
      },
      "outputs": [],
      "source": [
        "# # Viewing TensorBoard in Jupyter and Google Colab Notebooks (uncomment to view full TensorBoard instance)\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTyxSDDUMza2",
        "outputId": "9b1860dd-c843-43fe-8e45-d2e8b4ea82a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'models/01_vit16_50_epochs.pth' -> 'drive/MyDrive/emp/models/01_vit16_50_epochs.pth'\n"
          ]
        }
      ],
      "source": [
        "# %cp -av models drive/MyDrive/emp/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IaC_IHJPhgo"
      },
      "outputs": [],
      "source": [
        "# # Setup the best model filepath\n",
        "# best_model_path = \"models/07_effnetb2_data_20_percent_10_epochs.pth\"\n",
        "\n",
        "# # Instantiate a new instance of EffNetB2 (to load the saved state_dict() to)\n",
        "# best_model = create_effnetb2()\n",
        "\n",
        "# # Load the saved best model state_dict()\n",
        "# best_model.load_state_dict(torch.load(best_model_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bisoz6UuSlcV"
      },
      "outputs": [],
      "source": [
        "# # Check the model file size\n",
        "# from pathlib import Path\n",
        "\n",
        "# # Get the model size in bytes then convert to megabytes\n",
        "# effnetb2_model_size = Path(best_model_path).stat().st_size // (1024*1024)\n",
        "# print(f\"EfficientNetB2 feature extractor model size: {effnetb2_model_size} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "fiRPPwwfSloH",
        "outputId": "0d470f91-262b-4525-de7f-cdd5af8d4390"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'data_20_percent_path' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-2e42289302d4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnum_images_to_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtest_image_path_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_20_percent_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*/*.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get all test image paths from 20% dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m test_image_path_sample = random.sample(population=test_image_path_list,\n\u001b[1;32m     10\u001b[0m                                        k=num_images_to_plot) # randomly select k number of images\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data_20_percent_path' is not defined"
          ]
        }
      ],
      "source": [
        "# # Import function to make predictions on images and plot them\n",
        "# # See the function previously created in section: https://www.learnpytorch.io/06_pytorch_transfer_learning/#6-make-predictions-on-images-from-the-test-set\n",
        "# from going_modular.going_modular.predictions import pred_and_plot_image\n",
        "\n",
        "# # Get a random list of 3 images from 20% test set\n",
        "import random\n",
        "num_images_to_plot = 3\n",
        "test_image_path_list = list(Path(data_20_percent_path / \"test\").glob(\"*/*.jpg\")) # get all test image paths from 20% dataset\n",
        "test_image_path_sample = random.sample(population=test_image_path_list,\n",
        "                                       k=num_images_to_plot) # randomly select k number of images\n",
        "\n",
        "# Iterate through random test image paths, make predictions on them and plot them\n",
        "for image_path in test_image_path_sample:\n",
        "    pred_and_plot_image(model=best_model,\n",
        "                        image_path=image_path,\n",
        "                        class_names=class_names,\n",
        "                        image_size=(224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "ms1yc97KSwxo",
        "outputId": "4bf21c70-59e4-46f4-ec75-d62ce200389f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pred_and_plot_image' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-82da1b913502>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predict on custom image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m pred_and_plot_image(model=model,\n\u001b[0m\u001b[1;32m      3\u001b[0m                     \u001b[0mimage_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_image_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     class_names=class_names)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pred_and_plot_image' is not defined"
          ]
        }
      ],
      "source": [
        "# Predict on custom image\n",
        "pred_and_plot_image(model=model,\n",
        "                    image_path=custom_image_path,\n",
        "                    class_names=class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLudY9kWSw33"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7fxTOXqTTr9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d3a84a726a4c4a92bdc90db15d7e89cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c55ae56e713441caafcd1d924ca1904",
              "IPY_MODEL_a50ea1589c39430e924910b900584375",
              "IPY_MODEL_46da477fc610406ea75b9490391ed8ca"
            ],
            "layout": "IPY_MODEL_b26d7f1656f64ee8a2cc49c57991ebf9"
          }
        },
        "3c55ae56e713441caafcd1d924ca1904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2044f565b6274a49a0d33b2b7100d371",
            "placeholder": "​",
            "style": "IPY_MODEL_8e6cd7984424411ca2e386f1243d619f",
            "value": "100%"
          }
        },
        "a50ea1589c39430e924910b900584375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3332552953e64ca1a1ab48e2486c35d0",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c07dcbba560a40adbd136c7fc8dd7de7",
            "value": 50
          }
        },
        "46da477fc610406ea75b9490391ed8ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f9aa94a81e843c39643879132f6d069",
            "placeholder": "​",
            "style": "IPY_MODEL_c9afe4bd0bf24cc6b338dae8cc069223",
            "value": " 50/50 [07:23&lt;00:00,  8.91s/it]"
          }
        },
        "b26d7f1656f64ee8a2cc49c57991ebf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2044f565b6274a49a0d33b2b7100d371": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e6cd7984424411ca2e386f1243d619f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3332552953e64ca1a1ab48e2486c35d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c07dcbba560a40adbd136c7fc8dd7de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f9aa94a81e843c39643879132f6d069": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9afe4bd0bf24cc6b338dae8cc069223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}